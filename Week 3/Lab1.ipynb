{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6658482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import chi2, SelectKBest, RFE\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ac609ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv(\"Titanic-Dataset.csv\")\n",
    "\n",
    "# Separate Survived\n",
    "y = df[\"Survived\"].astype(int)\n",
    "X = df.drop(columns=[\"Survived\"])\n",
    "\n",
    "# Create a list of numeric and categorical variables\n",
    "# Will be used for the feature selection process\n",
    "# Names will not be used as they are irrelevant\n",
    "num_cols = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "cat_cols = [\"Pclass\", \"Sex\", \"Embarked\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b4fc956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction with Pipeline\n",
    "\n",
    "# Numeric Data\n",
    "num_tf = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical Data\n",
    "cat_tf = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b0cd2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FamilySize Feature\n",
    "X[\"FamilySize\"] = X[\"SibSp\"].fillna(0) + X[\"Parch\"].fillna(0) + 1\n",
    "\n",
    "# Add FamilySize to numeric group\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", num_tf, num_cols + [\"FamilySize\"]),\n",
    "    (\"cat\", cat_tf, cat_cols),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a100aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection with SelectKBest\n",
    "# That function will use variance analysis\n",
    "# Read: https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection\n",
    "\n",
    "from sklearn.feature_selection import f_classif\n",
    "selector_filter = SelectKBest(score_func=f_classif, k=5)\n",
    "\n",
    "# Create final pipeline (THIS IS ONLY PIPELINE, NOT PROCESSING DATA YET)\n",
    "pipe_filter = Pipeline([\n",
    "    (\"prep\", preprocess), # run pipeline preprocessing\n",
    "    (\"sel\", selector_filter), # run pipeline feature selection\n",
    "    (\"clf\", LogisticRegression(max_iter=1000)) # test using simple model -> Logistic Regression\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcd8c98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Filter (ANOVA) + LR ===\n",
      "Accuracy: 0.776536312849162\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82       110\n",
      "           1       0.73      0.67      0.70        69\n",
      "\n",
      "    accuracy                           0.78       179\n",
      "   macro avg       0.77      0.76      0.76       179\n",
      "weighted avg       0.77      0.78      0.77       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training and testing the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipe_filter.fit(X_train, y_train)\n",
    "pred = pipe_filter.predict(X_test)\n",
    "print(\"=== Filter (ANOVA) + LR ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f0f4d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nama fitur: ['num__Age' 'num__SibSp' 'num__Parch' 'num__Fare' 'num__FamilySize'\n",
      " 'cat__Pclass_1' 'cat__Pclass_2' 'cat__Pclass_3' 'cat__Sex_female'\n",
      " 'cat__Sex_male' 'cat__Embarked_C' 'cat__Embarked_Q' 'cat__Embarked_S']\n",
      "\n",
      "\n",
      "Top fitur: [('cat__Sex_female', 306.5932488951883), ('cat__Sex_male', 306.59324889518797), ('cat__Pclass_3', 80.33862734392042), ('cat__Pclass_1', 73.99727564291717), ('num__Fare', 58.31490728198491)]\n"
     ]
    }
   ],
   "source": [
    "# 1) Nama fitur setelah preprocess\n",
    "feat_names = pipe_filter.named_steps[\"prep\"].get_feature_names_out()\n",
    "print(\"Nama fitur:\", feat_names)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 2) Mask & skor fitur terpilih (SelectKBest)\n",
    "sel = pipe_filter.named_steps[\"sel\"]\n",
    "mask = sel.get_support()\n",
    "selected_names = feat_names[mask]\n",
    "selected_scores = sel.scores_[mask]\n",
    "top = sorted(zip(selected_names, selected_scores), key=lambda t: t[1], reverse=True)[:10]\n",
    "print(\"Top fitur:\", top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
